{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minnesota Timberwolves' Top 20 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=lAHvS1nfpb8\n",
      "Cleveland Cavaliers' Top 25 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=4dcH7cajFFg\n",
      "Stephen Curry's Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=T_Sj89528ms\n",
      "Denver Nuggets' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=EbXd3rMPbg8\n",
      "Boston Celtics' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=Z3F7hg22c4Q\n",
      "Atlanta Hawks' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=XzZd_W4ix2I\n",
      "Top 50 Blocks of the 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=t991kajkFog\n",
      "Top 40 Long Distance Shots of the 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=iEQbtcgWwyo\n",
      "Top 80 Assists of the 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=axN_Kdvxdds\n",
      "Manu Ginobili's Top 10 Impossible Shots of His Career!\n",
      "https://www.youtube.com/watch?v=lljjd8jFck8\n",
      "Manu Ginobili's Early San Antonio Career Look Back\n",
      "https://www.youtube.com/watch?v=0aPJaWQJ2Tw\n",
      "Detroit Pistons' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=Fry26YdEs-w\n",
      "Chicago Bulls' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=79ebeRyKa8k\n",
      "Top 10 Crossovers: 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=aC72YYjkuJw\n",
      "Top 10 Dunks: 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=_XaxyIWS6G8\n",
      "Milwaukee Bucks' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=BhpVibrcuBA\n",
      "Indiana Pacers' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=-KbjkCCjc84\n",
      "Houston Rockets' Top 25 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=WzcHEcwNyvw\n",
      "Layshia Clarendon Has HUGE Game After All Star | 15pts 10rebs and 9asts\n",
      "https://www.youtube.com/watch?v=YvzoopAipzw\n",
      "New Orleans Pelicans' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=3JOyhiT6va8\n",
      "San Antonio Spurs' Top 25 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=MYeHuY6BTYk\n",
      "Top 60 Clutch Shots: 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=kfhmEe20xgY\n",
      "Remembering John Kundla\n",
      "https://www.youtube.com/watch?v=DZ7qnNiFe4c\n",
      "John Wall’s INSANE 2016-2017 NBA MIXTAPE\n",
      "https://www.youtube.com/watch?v=JZQd5Ofr9Fo\n",
      "Dallas Mavericks' Top 10 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=1-0JkphG0PY\n",
      "Memphis Grizzlies' Top 20 Plays of the 2016-2017 NBA Season\n",
      "https://www.youtube.com/watch?v=4cu3ERfsDnI\n",
      "Top 100 Crossovers: 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=whRHdXCS9eE\n",
      "Top 100 Dunks: 2017 NBA Season\n",
      "https://www.youtube.com/watch?v=TwYTnXsAsoI\n",
      "DeAndre Jordan Top 10 Career Dunks\n",
      "https://www.youtube.com/watch?v=tdyny1rK0J0\n",
      "NBA Las Vegas Summer League Best All Access\n",
      "https://www.youtube.com/watch?v=_uvsetULWgA\n",
      "Total running time: 0.021567984422 minutes\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import urllib\n",
    "import lxml\n",
    "import requests\n",
    "\n",
    "# check start time to calculate running time\n",
    "start_time = time.time()\n",
    "\n",
    "nba_video_info = {\n",
    "    'title': '',\n",
    "    'video_link': '',\n",
    "    'img_link': '',\n",
    "    'play_time': '',\n",
    "    'hits': '',\n",
    "    'updated_time': ''\n",
    "}\n",
    "\n",
    "def get_nba_video_link(target_url):\n",
    "    response = requests.get(target_url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    lis = soup.find_all('li', {'class': 'channels-content-item yt-shelf-grid-item'})\n",
    "    for li in lis:\n",
    "        title = li.find('a', {'title': True})['title']\n",
    "        video_link = 'https://www.youtube.com' + li.find('a', {'href': True})['href']\n",
    "        \"\"\"title, videolink\n",
    "        <a class=\"yt-uix-sessionlink yt-uix-tile-link  spf-link  yt-ui-ellipsis yt-ui-ellipsis-2\" \n",
    "        dir=\"ltr\" title=\"Cleveland Cavaliers' Top 25 Plays of the 2016-2017 NBA Season\" \n",
    "        aria-describedby=\"description-id-568300\"\n",
    "        data-sessionlink=\"ei=im6BWaOMOceAqQHl-r2oDA&feature=c4-videos-u&ved=CDgQlx4iEwij-f3H87fVAhVHQCoKHWV9D8Uomxw\"\n",
    "        href=\"/watch?v=4dcH7cajFFg\">\n",
    "        \"Cleveland Cavaliers' Top 25 Plays of the 2016-2017 NBA Season\"\n",
    "        </a> \n",
    "        \"\"\"\n",
    "        img_link = li.find('img', {'src': True})['src']\n",
    "        '''img\n",
    "        <img aria-hidden=\"true\" \n",
    "        width=\"196\" \n",
    "        alt onload=\";window.__ytRIL && __ytRIL(this)\" \n",
    "        data-ytimg=\"1\"\n",
    "        src=\"https://i.ytimg.com/vi/4dcH7cajFFg/hqdefault.jpg?sqp=-oaymwEWCMQBEG5IWvKriqkDCQgBFQAAiEIYAQ==&rs=AOn4CLD7xJlecR1bz1IiSS7UsOHApBuQNg\"\n",
    "        >\n",
    "        '''\n",
    "\n",
    "        # play_time = li.find('span', {'class' : 'video-time-overlay video-time-overlay-default'}).text\n",
    "        play_time = li.find('span', {'class': 'video-time'}).text\n",
    "        '''play time\n",
    "        <span class=\"video-time-overlay video-time-overlay-default\" aria-hidden=\"true\">\n",
    "        <span aria-label=\"6 minutes, 38 seconds\">6:38</span></span>\n",
    "        '''\n",
    "\n",
    "        hits = li.find_all('li')[2].text\n",
    "        updated_time = li.find_all('li')[3].text\n",
    "        '''hits & updated_time\n",
    "        <ul class=\"yt-lockup-meta-info\">\n",
    "            <li>56,516 views></li>\n",
    "            <li>12 hours ago</li>\n",
    "        </ul>\n",
    "        hits_and_updated_time = li.find('ul',{'class': 'yt-lockup-meta-info'})\n",
    "        '''\n",
    "\n",
    "        nba_video_info = {\n",
    "            'title': title,\n",
    "            'video_link': video_link,\n",
    "            'img_link': img_link,\n",
    "            'play_time': play_time,\n",
    "            'hits': hits,\n",
    "            'updated_time': updated_time\n",
    "        }\n",
    "        # print all values\n",
    "        # print(nba_video_info)\n",
    "\n",
    "        # print title and video link\n",
    "        print(nba_video_info['title'])\n",
    "        print(nba_video_info['video_link'])\n",
    "        # print(\"title: %s, video_link: $s\" % (str(nba_video_info['title']), str(nba_video_info['video_link'])))\n",
    "        # print(\"title: {0}, video_link: {1}\".format(nba_video_info['title'], nba_video_info['video_link'])\n",
    "    return nba_video_info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    target_url = 'https://www.youtube.com/user/NBA/videos'\n",
    "    get_nba_video_link(target_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# initialize url addresses to crawl\n",
    "home_url = \"https://www.youtube.com/\"\n",
    "target_url = \"user/NBA/videos\" # target page url\n",
    "open_url = \"https://www.youtube.com/user/NBA/videos\" # attatch the remaining address to open\n",
    "image = \"\" # image source url\n",
    "count = 0\n",
    "print(open_url)\n",
    "\n",
    "# Build web browser with selenium.\n",
    "# Assign your path where the webdriver file located to 'executable_path' as String\n",
    "driver = webdriver.Firefox(executable_path='/usr/local/bin/geckodriver')\n",
    "driver.get(open_url)\n",
    "\n",
    "# Build bs4\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# calculating time taken\n",
    "end_time = time.time()\n",
    "running_time = end_time-start_time\n",
    "print(\"Total running time: {0} minutes\".format(running_time / 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom bs4 import BeautifulSoup\\nfrom selenium import webdriver\\n# import datetime\\n# import time\\n# import csv\\n\\n\\n# check start time to calculate running time\\nstart_time = time.time()\\n\\n# initialize url addresses to crawl\\nhome_url = \"https://www.instagram.com/\"\\nopen_url = home_url + \" \" # attatch the remaining address to open\\ntarget_url = \"\" # target page url\\nimage = \"\" # image source url\\ncount = 0\\n\\n# Build web browser with selenium.\\n# Assign your path where the webdriver file located to \\'executable_path\\' as String\\ndriver = webdriver.Firefox(executable_path=\\'/usr/local/bin/geckodriver\\')\\ndriver.get(open_url)\\n\\n# Build bs4\\nsoup = BeautifulSoup(driver.page_source, \\'lxml\\')\\n\\n# see more\\nelement = driver.find_element_by_class_name(\\'_8imhp\\')\\nelement.click()\\nitems_len = 0\\nwhile(1):\\n    for i in range(3):\\n        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\\n        time.sleep(1.5) # waiting interval\\n    \\n    # Build bs4\\n    soup = BeautifulSoup(driver.page_source, \\'lxml\\')\\n    items = soup.find_all(\"div\", class_=\"_8mlbc _vbtk2 _t5r8b\")\\n    if items_len != len(items):\\n        items_len = len(items)\\n        print(\"number of items: \" + str(items_len))\\n    elif items_len == len(items):\\n        print(\"end of page\")\\n        break\\n    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\\n    \\nf = open(\\'/Users/choiyoungrok/OneDrive/Data_Science/dataset/instagram_downtwnr.csv\\', \\'w\\')\\nwr = csv.writer(f)\\nwr.writerow([\\'uid\\', \\'datetime\\', \\'likes\\', \\'location\\', \\'account\\', \\'tags\\', \\'comments\\', \\'image\\'])\\nf.close()    \\n\\nfor x in items:\\n    count += 1\\n    uid = \"\"\\n    tags = \"\"\\n    datetime = None\\n    likes = None\\n    location = None\\n    account = None\\n    comments = \"\"\\n    \\n    # URL\\n    target_url = x.get(\\'href\\').split(\\'?\\')[0]\\n    uid = target_url.split(\"/\")[2]\\n    target_url = open_url + target_url\\n    driver.get(target_url)\\n    \\n    # Image\\n    image = x.find(\"div\", class_=\"_22yr2\").find(\"div\", class_=\"_jjzlb\").find(\"img\").get(\"src\")\\n    \\n    # Open Target Page\\n    soup2 = BeautifulSoup(driver.page_source, \\'lxml\\')\\n    # Time\\n    if soup2.find(\"time\") != None:\\n        datetime = soup2.find(\"time\").get(\\'datetime\\')\\n    \\n    # Location\\n    location_container = soup2.find(\"a\", class_=\"_kul9p _mg7fs\")\\n    if location_container != None:\\n        location = location_container.get(\\'href\\').split(\\'/\\')[3]+\\'$\\'+location_container.get(\\'title\\').encode(\\'utf-8\\')\\n    \\n    # Account\\n    if soup2.find(\"a\", class_=\"_4zhc5 notranslate _jozwt\") != None:\\n        account = soup2.find(\"a\", class_=\"_4zhc5 notranslate _jozwt\").get(\\'title\\')\\n    \\n    # Tag\\n    tags_container = soup2.find_all(\"a\")\\n    for tag in tags_container:\\n        if (tag.get(\\'href\\') != None) and (\\'#\\' in tag.getText()):\\n                tags += tag.getText()\\n    \\n    if soup2.find(\"div\", class_=\"_kkf84 _oajsw\") == None: # if nobody likes yet\\n        likes = 0\\n    else: # caculating small number of likes\\n        like_container = soup2.find(\"div\", class_=\"_kkf84 _oajsw\").find(\"span\", class_=\"_tf9x3\")\\n        if like_container == None:\\n            likes = len(soup2.find(\"div\", class_=\"_kkf84 _oajsw\").find_all(\"a\"))\\n        elif like_container.find(\"span\") != None:\\n            likes = like_container.find(\"span\").getText()\\n        else: # https://www.instagram.com/p/6ZON55AFfa/\\n            likes = like_container.getText().encode(\\'utf-8\\')[-4:-3]\\n\\n    \\n    # comments\\n    if soup2.find(\"button\", class_=\"_jpmen _8zx0v\") != None: # check if \\'\\xeb\\x8c\\x93\\xea\\xb8\\x80 \\xeb\\x8d\\x94 \\xeb\\xb3\\xb4\\xea\\xb8\\xb0 exists\\n        element = driver.find_element_by_class_name(\\'_jpmen\\')\\n        element.click() \\n        \\n    comments_container = soup2.find_all(\"li\", class_=\"_99ch8\")\\n    if comments_container != None:\\n        for comment in comments_container:\\n            if comment.find(\"a\", class_=\"_4zhc5 notranslate _ebg8h\") != None:\\n                comments = comments + \"<^\" + comment.find(\"a\", class_=\"_4zhc5 notranslate _ebg8h\").get(\\'title\\') + \">$\"\\n                # indentifier(<^: account, >$: text)\\n                comments = comments + comment.span.getText()\\n    \\n    print(\"===={}====\").format(count)\\n    print(\"uid: {}\").format(uid)\\n    \\n    #print(\"url: {}\").format(target_url)\\n    print(\"datetime: {}\").format(datetime)\\n    #print(\"likes: {}\").format(likes)\\n    #pprint(location)\\n    #print(\"image: {}\").format(image)\\n    #print(\"account: {}\").format(account)\\n    #print(tags)\\n    #print(comments)\\n    #print(\" \")\\n    \\n    f = open(\\'/Users/choiyoungrok/OneDrive/Data_Science/dataset/instagram_downtwnr.csv\\', \\'a\\')\\n    wr = csv.writer(f)\\n    wr.writerow([uid, datetime, likes, location, account, tags.encode(\\'utf-8\\'), comments.encode(\\'utf-8\\')])\\n    f.close()\\n\\nend_time = time.time()\\nrunning_time = end_time - start_time\\nprint(\"Total running time: {} minutes\").format(running_time / 60)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#-*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "# import datetime\n",
    "# import time\n",
    "# import csv\n",
    "\n",
    "\n",
    "# check start time to calculate running time\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize url addresses to crawl\n",
    "home_url = \"https://www.instagram.com/\"\n",
    "open_url = home_url + \" \" # attatch the remaining address to open\n",
    "target_url = \"\" # target page url\n",
    "image = \"\" # image source url\n",
    "count = 0\n",
    "\n",
    "# Build web browser with selenium.\n",
    "# Assign your path where the webdriver file located to 'executable_path' as String\n",
    "driver = webdriver.Firefox(executable_path='/usr/local/bin/geckodriver')\n",
    "driver.get(open_url)\n",
    "\n",
    "# Build bs4\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# see more\n",
    "element = driver.find_element_by_class_name('_8imhp')\n",
    "element.click()\n",
    "items_len = 0\n",
    "while(1):\n",
    "    for i in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.5) # waiting interval\n",
    "    \n",
    "    # Build bs4\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    items = soup.find_all(\"div\", class_=\"_8mlbc _vbtk2 _t5r8b\")\n",
    "    if items_len != len(items):\n",
    "        items_len = len(items)\n",
    "        print(\"number of items: \" + str(items_len))\n",
    "    elif items_len == len(items):\n",
    "        print(\"end of page\")\n",
    "        break\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "f = open('/Users/choiyoungrok/OneDrive/Data_Science/dataset/instagram_downtwnr.csv', 'w')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['uid', 'datetime', 'likes', 'location', 'account', 'tags', 'comments', 'image'])\n",
    "f.close()    \n",
    "\n",
    "for x in items:\n",
    "    count += 1\n",
    "    uid = \"\"\n",
    "    tags = \"\"\n",
    "    datetime = None\n",
    "    likes = None\n",
    "    location = None\n",
    "    account = None\n",
    "    comments = \"\"\n",
    "    \n",
    "    # URL\n",
    "    target_url = x.get('href').split('?')[0]\n",
    "    uid = target_url.split(\"/\")[2]\n",
    "    target_url = open_url + target_url\n",
    "    driver.get(target_url)\n",
    "    \n",
    "    # Image\n",
    "    image = x.find(\"div\", class_=\"_22yr2\").find(\"div\", class_=\"_jjzlb\").find(\"img\").get(\"src\")\n",
    "    \n",
    "    # Open Target Page\n",
    "    soup2 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    # Time\n",
    "    if soup2.find(\"time\") != None:\n",
    "        datetime = soup2.find(\"time\").get('datetime')\n",
    "    \n",
    "    # Location\n",
    "    location_container = soup2.find(\"a\", class_=\"_kul9p _mg7fs\")\n",
    "    if location_container != None:\n",
    "        location = location_container.get('href').split('/')[3]+'$'+location_container.get('title').encode('utf-8')\n",
    "    \n",
    "    # Account\n",
    "    if soup2.find(\"a\", class_=\"_4zhc5 notranslate _jozwt\") != None:\n",
    "        account = soup2.find(\"a\", class_=\"_4zhc5 notranslate _jozwt\").get('title')\n",
    "    \n",
    "    # Tag\n",
    "    tags_container = soup2.find_all(\"a\")\n",
    "    for tag in tags_container:\n",
    "        if (tag.get('href') != None) and ('#' in tag.getText()):\n",
    "                tags += tag.getText()\n",
    "    \n",
    "    if soup2.find(\"div\", class_=\"_kkf84 _oajsw\") == None: # if nobody likes yet\n",
    "        likes = 0\n",
    "    else: # caculating small number of likes\n",
    "        like_container = soup2.find(\"div\", class_=\"_kkf84 _oajsw\").find(\"span\", class_=\"_tf9x3\")\n",
    "        if like_container == None:\n",
    "            likes = len(soup2.find(\"div\", class_=\"_kkf84 _oajsw\").find_all(\"a\"))\n",
    "        elif like_container.find(\"span\") != None:\n",
    "            likes = like_container.find(\"span\").getText()\n",
    "        else: # https://www.instagram.com/p/6ZON55AFfa/\n",
    "            likes = like_container.getText().encode('utf-8')[-4:-3]\n",
    "\n",
    "    \n",
    "    # comments\n",
    "    if soup2.find(\"button\", class_=\"_jpmen _8zx0v\") != None: # check if '댓글 더 보기 exists\n",
    "        element = driver.find_element_by_class_name('_jpmen')\n",
    "        element.click() \n",
    "        \n",
    "    comments_container = soup2.find_all(\"li\", class_=\"_99ch8\")\n",
    "    if comments_container != None:\n",
    "        for comment in comments_container:\n",
    "            if comment.find(\"a\", class_=\"_4zhc5 notranslate _ebg8h\") != None:\n",
    "                comments = comments + \"<^\" + comment.find(\"a\", class_=\"_4zhc5 notranslate _ebg8h\").get('title') + \">$\"\n",
    "                # indentifier(<^: account, >$: text)\n",
    "                comments = comments + comment.span.getText()\n",
    "    \n",
    "    print(\"===={}====\").format(count)\n",
    "    print(\"uid: {}\").format(uid)\n",
    "    \n",
    "    #print(\"url: {}\").format(target_url)\n",
    "    print(\"datetime: {}\").format(datetime)\n",
    "    #print(\"likes: {}\").format(likes)\n",
    "    #pprint(location)\n",
    "    #print(\"image: {}\").format(image)\n",
    "    #print(\"account: {}\").format(account)\n",
    "    #print(tags)\n",
    "    #print(comments)\n",
    "    #print(\" \")\n",
    "    \n",
    "    f = open('/Users/choiyoungrok/OneDrive/Data_Science/dataset/instagram_downtwnr.csv', 'a')\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([uid, datetime, likes, location, account, tags.encode('utf-8'), comments.encode('utf-8')])\n",
    "    f.close()\n",
    "\n",
    "end_time = time.time()\n",
    "running_time = end_time - start_time\n",
    "print(\"Total running time: {} minutes\").format(running_time / 60)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
